{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing, svm, metrics, tree\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from ydata_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.markers as markers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the backend to TkAgg for interactive plotting\n",
        "plt.switch_backend('TkAgg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "df.head(10):\n",
            "\n",
            "    current      R      G      B\n",
            "0  0.124718  0.000  0.000  0.082\n",
            "1  0.336410  0.000  0.000  0.333\n",
            "2  0.084220  0.000  0.000  0.000\n",
            "3  0.465096  0.498  0.000  0.000\n",
            "4  0.447505  0.000  0.165  0.333\n",
            "5  0.440049  0.247  0.165  0.082\n",
            "6  0.553050  0.498  0.165  0.000\n",
            "7  0.340914  0.000  0.000  0.333\n",
            "8  0.126161  0.000  0.000  0.082\n",
            "9  0.465773  0.498  0.000  0.000\n"
          ]
        }
      ],
      "source": [
        "# Read the data file\n",
        "df = pd.read_csv(\"./labeled_dataset.csv\", sep=',')\n",
        "\n",
        "# Print the data for verification\n",
        "print('\\n\\ndf.head(10):\\n')\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# d = df\n",
        "\n",
        "# # Generate a report for Pandas Dataframe analysis using the ydata profiling library\n",
        "# profile = ProfileReport(d, title=\"Pandas Profiling Report\")\n",
        "# profile.to_notebook_iframe()\n",
        "# profile.to_file(\"report.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        }
      ],
      "source": [
        "d = df\n",
        "\n",
        "# Select rows where both conditions are True\n",
        "d_filtered = d[(d['G'] == 0) & (d['B'] == 0)]\n",
        "d_filtered = d_filtered.copy().drop(columns=['G', 'B'])\n",
        "\n",
        "d_g = d[(d['R'] == 0) & (d['B'] == 0)]\n",
        "d_g = d_g.copy().drop(columns=['R', 'B'])\n",
        "\n",
        "d_b = d[(d['R'] == 0) & (d['G'] == 0)]\n",
        "d_b = d_b.copy().drop(columns=['R', 'G'])\n",
        "\n",
        "# Create the plot\n",
        "colors = ['red', 'green', 'blue']\n",
        "marker = ['o', 'o', 'o']\n",
        "marker_size = [20, 20, 20]\n",
        "alpha = 1.0  # Transparency\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))  # Adjust figsize as needed\n",
        "\n",
        "index = 0\n",
        "for col, data, ax in zip(colors, [d_filtered, d_g, d_b], axes):\n",
        "    ax.scatter(data['current'], data.iloc[:, 1], color=col, alpha=alpha, marker=marker[index], s=marker_size[index])\n",
        "    index += 1\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot (without clearing)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "d = df\n",
        "\n",
        "# Select rows where both conditions are True\n",
        "d_filtered = d[(d['G'] == 0) & (d['B'] == 0)]\n",
        "d_filtered = d_filtered.copy().drop(columns=['G', 'B'])\n",
        "\n",
        "d_g = d[(d['R'] == 0) & (d['B'] == 0)]\n",
        "d_g = d_g.copy().drop(columns=['R', 'B'])\n",
        "\n",
        "d_b = d[(d['R'] == 0) & (d['G'] == 0)]\n",
        "d_b = d_b.copy().drop(columns=['R', 'G'])\n",
        "\n",
        "# Create the plot\n",
        "colors = ['red', 'green', 'blue']\n",
        "marker = ['o', 'o', 'o']\n",
        "marker_size = [125, 75, 25]\n",
        "alpha = 0.33  # Transparency\n",
        "\n",
        "index = 0\n",
        "for col, data in zip(colors, [d_filtered, d_g, d_b]):\n",
        "    plt.scatter(data['current'], data.iloc[:, 1], label=col, color=col, alpha=alpha, marker=marker[index], s=marker_size[index])\n",
        "    index += 1\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Current')\n",
        "plt.ylabel('Color Channel Value')\n",
        "plt.title('Scatter Plot with Transparency and Circle Markers (R, G, B)')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Clear the plot for the next iteration\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.005979767308785969\n",
            "Predicted R for new values: [0.08702744 0.25832013 0.42286651]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler  # For data normalization\n",
        "import matplotlib.pyplot as plt  # For visualization\n",
        "\n",
        "# Assuming your data is loaded into a pandas DataFrame called 'df'\n",
        "\n",
        "# Filter data (replace with your filtering criteria)\n",
        "d_filtered = df[(df['G'] == 0) & (df['B'] == 0)]\n",
        "d_filtered = d_filtered.copy().drop(columns=['G', 'B'])\n",
        "\n",
        "# Select features and target\n",
        "X = d_filtered['current'].to_numpy().reshape(-1, 1)  # Reshape for SVM\n",
        "y = d_filtered['R'].to_numpy()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data (SVR can be sensitive to feature scales)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the SVR model\n",
        "model = SVR(kernel='rbf', gamma=0.1)  # You can adjust kernel and gamma for better performance\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predicted_R = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance (optional)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(y_test, predicted_R)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Visualization\n",
        "\n",
        "# Plot actual vs predicted R values\n",
        "plt.scatter(y_test, predicted_R)\n",
        "plt.xlabel(\"Actual R\")\n",
        "plt.ylabel(\"Predicted R\")\n",
        "plt.title(\"Actual vs. Predicted R Values\")\n",
        "plt.show()\n",
        "\n",
        "# Predict R for new data points (replace with your actual values)\n",
        "new_current_values = [0.1, 0.3, 0.5]  # Example values\n",
        "new_current_values = np.array(new_current_values).reshape(-1, 1)  # Reshape for prediction\n",
        "predicted_R_new = model.predict(scaler.transform(new_current_values))  # Apply normalization\n",
        "\n",
        "print(\"Predicted R for new values:\", predicted_R_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler  # For data normalization\n",
        "import matplotlib.pyplot as plt  # For visualization\n",
        "\n",
        "# Assuming your data is loaded into a pandas DataFrame called 'df'\n",
        "\n",
        "# Filter data (replace with your filtering criteria)\n",
        "d_filtered = df[(df['G'] == 0) & (df['B'] == 0)]\n",
        "d_filtered = d_filtered.copy().drop(columns=['G', 'B'])\n",
        "\n",
        "# Select features and target\n",
        "X = d_filtered.drop('R', axis=1)  # All columns except 'R' as features\n",
        "y = d_filtered['R'].to_numpy()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data (Random Forest can be beneficial with normalized data)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the Random Forest Regression model\n",
        "model = RandomForestRegressor(n_estimators=10, random_state=42)  # You can adjust n_estimators\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predicted_R = model.predict(X_test)\n",
        "\n",
        "# Visualization: Predicted vs. Actual R Values with Annotations\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size for better readability\n",
        "\n",
        "# Set marker size and color for data points\n",
        "marker_size = 20  # Twice the current size\n",
        "plt.scatter(y_test, predicted_R, s=marker_size, c='red')\n",
        "\n",
        "plt.xlabel(\"Actual R\")\n",
        "plt.ylabel(\"Predicted R\")\n",
        "plt.title(\"Predicted vs. Actual R Values\")\n",
        "\n",
        "# Add annotations for each data point (actual, predicted, difference)\n",
        "font_size = 16  # Desired font size\n",
        "\n",
        "for i, (actual_value, predicted_value) in enumerate(zip(y_test, predicted_R)):\n",
        "    difference = abs(actual_value - predicted_value)\n",
        "    annotation_text = f\"Actual: {actual_value:.2f}\\nPredicted: {predicted_value:.2f}\\nDiff: {difference:.2f}\"\n",
        "    plt.annotate(annotation_text, (actual_value, predicted_value), textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=font_size)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       current      R      G\n",
            "2     0.084220  0.000  0.000\n",
            "3     0.465096  0.498  0.000\n",
            "6     0.553050  0.498  0.165\n",
            "9     0.465773  0.498  0.000\n",
            "11    0.086393  0.000  0.000\n",
            "...        ...    ...    ...\n",
            "5926  0.287018  0.247  0.000\n",
            "5929  0.411830  0.247  0.165\n",
            "5930  0.533520  0.247  0.416\n",
            "5931  0.293261  0.247  0.000\n",
            "5932  0.404516  0.000  0.416\n",
            "\n",
            "[2471 rows x 3 columns]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "(0.498, 0.165)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[88], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define target labels for each scenario (one-hot encoding or integer labels)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m target_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m): \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# Both off\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     (\u001b[38;5;241m0.498\u001b[39m, \u001b[38;5;241m0\u001b[39m): \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Only R on\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.416\u001b[39m): \u001b[38;5;241m2\u001b[39m   \u001b[38;5;66;03m# Only G on\u001b[39;00m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(d)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[88], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define target labels for each scenario (one-hot encoding or integer labels)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m target_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m): \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# Both off\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     (\u001b[38;5;241m0.498\u001b[39m, \u001b[38;5;241m0\u001b[39m): \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Only R on\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.416\u001b[39m): \u001b[38;5;241m2\u001b[39m   \u001b[38;5;66;03m# Only G on\u001b[39;00m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m d[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mtarget_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(d)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.498, 0.165)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier  # You can experiment with other classifiers\n",
        "from sklearn.preprocessing import StandardScaler  # For data normalization\n",
        "\n",
        "# Assuming your data is loaded into a pandas DataFrame called 'df'\n",
        "\n",
        "\n",
        "\n",
        "d = df[(df['B'] == 0)].copy().drop(columns='B')\n",
        "print(d)\n",
        "\n",
        "# Define target labels for each scenario (one-hot encoding or integer labels)\n",
        "target_labels = {\n",
        "    (0, 0): 0,  # Both off\n",
        "    (0.498, 0): 1,  # Only R on\n",
        "    (0, 0.416): 2   # Only G on\n",
        "}\n",
        "\n",
        "d['target'] = d[['R', 'G']].apply(lambda row: target_labels[tuple(row)], axis=1)\n",
        "\n",
        "print(d)\n",
        "\n",
        "# Separate features and target\n",
        "X = d.drop(['target'], axis=1)  # Current value as feature\n",
        "y = d['target'].to_numpy()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize data (can be beneficial for classification models)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the Random Forest Classifier model (you can adjust hyperparameters)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predicted_labels = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance (optional)\n",
        "# You can use classification metrics like accuracy, precision, recall, etc.\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# accuracy = accuracy_score(y_test, predicted_labels)\n",
        "# print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Apply the model to new data with noisy current values\n",
        "def predict_scenario(current):\n",
        "  # Preprocess the new data (scale if needed)\n",
        "  current_scaled = scaler.transform([[current]])\n",
        "  # Predict the label\n",
        "  predicted_label = model.predict(current_scaled)[0]\n",
        "  # Translate label back to scenario description (optional)\n",
        "  scenario_map = {0: \"Both Off\", 1: \"Only R On\", 2: \"Only G On\"}\n",
        "  return scenario_map[predicted_label]\n",
        "\n",
        "# Example usage with a new current value (including potential noise)\n",
        "new_current = 0.48  # Example with some noise (replace with your actual value)\n",
        "predicted_scenario = predict_scenario(new_current)\n",
        "print(f\"Predicted Scenario for current {new_current}: {predicted_scenario}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
